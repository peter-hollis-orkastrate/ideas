/**
 * Health Check MCP Tools
 *
 * Tools: ocr_health_check
 *
 * Detects data integrity gaps and optionally triggers fixes.
 * Internal-only - no external API calls needed.
 *
 * CRITICAL: NEVER use console.log() - stdout is reserved for JSON-RPC protocol.
 * Use console.error() for all logging.
 *
 * @module tools/health
 */

import { z } from 'zod';
import { requireDatabase } from '../server/state.js';
import { successResult } from '../server/types.js';
import { validateInput } from '../utils/validation.js';
import { formatResponse, handleError, type ToolResponse, type ToolDefinition } from './shared.js';

// ═══════════════════════════════════════════════════════════════════════════════
// INPUT SCHEMAS
// ═══════════════════════════════════════════════════════════════════════════════

const HealthCheckInput = z.object({
  fix: z
    .boolean()
    .default(false)
    .describe(
      'If true, trigger processing for fixable gaps (chunks without embeddings). Other gaps are reported but need manual intervention via specific tools.'
    ),
});

// ═══════════════════════════════════════════════════════════════════════════════
// TYPE DEFINITIONS
// ═══════════════════════════════════════════════════════════════════════════════

/** Gap category with counts and sample IDs */
interface GapCategory {
  count: number;
  sample_ids: string[];
  fixable: boolean;
  fix_tool: string | null;
  fix_hint: string | null;
}

// ═══════════════════════════════════════════════════════════════════════════════
// HANDLER: ocr_health_check
// ═══════════════════════════════════════════════════════════════════════════════

/**
 * Handle ocr_health_check - Detect and optionally fix data integrity gaps
 *
 * Checks for:
 * 1. Chunks without embeddings (fixable via embedding generation)
 * 2. Documents without OCR results (non-pending status)
 * 3. Images without VLM descriptions
 * 4. Embeddings without vectors in vec_embeddings
 * 5. Orphaned provenance records
 */
async function handleHealthCheck(params: Record<string, unknown>): Promise<ToolResponse> {
  try {
    const input = validateInput(HealthCheckInput, params);
    const { db, vector } = requireDatabase();
    const conn = db.getConnection();

    const gaps: Record<string, GapCategory> = {};
    const fixes: string[] = [];
    const fixFailures: Array<{ fix: string; error: string }> = [];
    const SAMPLE_LIMIT = 10;

    // ──────────────────────────────────────────────────────────────
    // Environment Variable Verification
    // ──────────────────────────────────────────────────────────────
    const envStatus = (globalThis as Record<string, unknown>).__OCR_ENV_STATUS as
      | {
          datalab_api_key: boolean;
          gemini_api_key: boolean;
          checked_at: string;
        }
      | undefined;

    const environment: Record<string, unknown> = {
      datalab_api_key: !!process.env.DATALAB_API_KEY,
      gemini_api_key: !!process.env.GEMINI_API_KEY,
      embedding_model_path: process.env.EMBEDDING_MODEL_PATH ?? null,
      embedding_device: process.env.EMBEDDING_DEVICE ?? 'auto',
      is_docker:
        !!process.env.OCR_PROVENANCE_DATABASES_PATH || !!process.env.OCR_PROVENANCE_ALLOWED_DIRS,
      startup_check: envStatus ?? null,
    };

    const envWarnings: string[] = [];
    if (!process.env.DATALAB_API_KEY) {
      envWarnings.push(
        'DATALAB_API_KEY is not set — OCR processing (ocr_process_pending, ocr_convert_raw, ocr_reprocess, ocr_form_fill) will fail'
      );
    }
    if (!process.env.GEMINI_API_KEY) {
      envWarnings.push(
        'GEMINI_API_KEY is not set — VLM processing (ocr_vlm_describe, ocr_vlm_process, ocr_vlm_analyze_pdf, ocr_evaluate) will fail'
      );
    }

    // ──────────────────────────────────────────────────────────────
    // Gap 1: Chunks without embeddings
    // ──────────────────────────────────────────────────────────────
    const chunksWithoutEmbeddings = conn
      .prepare(
        `SELECT c.id FROM chunks c
       LEFT JOIN embeddings e ON e.chunk_id = c.id
       WHERE e.id IS NULL AND c.embedding_status != 'complete'`
      )
      .all() as Array<{ id: string }>;

    gaps.chunks_without_embeddings = {
      count: chunksWithoutEmbeddings.length,
      sample_ids: chunksWithoutEmbeddings.slice(0, SAMPLE_LIMIT).map((r) => r.id),
      fixable: true,
      fix_tool: 'ocr_process_pending',
      fix_hint: 'Set fix=true to trigger embedding generation',
    };

    // Fix: Generate embeddings for chunks missing them
    if (input.fix && chunksWithoutEmbeddings.length > 0) {
      try {
        const { getEmbeddingService } = await import('../services/embedding/embedder.js');
        const embeddingService = getEmbeddingService();

        // Get pending chunks (those with embedding_status != 'complete')
        const pendingChunks = db.getPendingEmbeddingChunks(100);

        if (pendingChunks.length > 0) {
          // Group chunks by document for proper provenance
          const chunksByDoc = new Map<string, typeof pendingChunks>();
          for (const chunk of pendingChunks) {
            const existing = chunksByDoc.get(chunk.document_id);
            if (existing) {
              existing.push(chunk);
            } else {
              chunksByDoc.set(chunk.document_id, [chunk]);
            }
          }

          let totalEmbedded = 0;
          for (const [docId, docChunks] of chunksByDoc.entries()) {
            const doc = db.getDocument(docId);
            if (!doc) {
              console.error(
                `[HealthCheck] Document ${docId} not found, skipping ${docChunks.length} chunks`
              );
              continue;
            }

            try {
              const result = await embeddingService.embedDocumentChunks(db, vector, docChunks, {
                documentId: doc.id,
                filePath: doc.file_path,
                fileName: doc.file_name,
                fileHash: doc.file_hash,
                documentProvenanceId: doc.provenance_id,
              });
              totalEmbedded += result.totalChunks;
            } catch (embedError) {
              // M-16: Track fix failures separately instead of "FAILED:" prefix strings
              console.error(
                `[HealthCheck] Failed to embed chunks for ${docId}: ${String(embedError)}`
              );
              fixFailures.push({
                fix: `Embedding generation for document ${docId}`,
                error: String(embedError),
              });
            }
          }

          if (totalEmbedded > 0) {
            fixes.push(
              `Generated embeddings for ${totalEmbedded} chunks across ${chunksByDoc.size} documents`
            );
          }
        }
      } catch (serviceError) {
        // M-16: Track fix failures separately instead of "FAILED:" prefix strings
        console.error(
          `[HealthCheck] Embedding service initialization failed: ${String(serviceError)}`
        );
        fixFailures.push({
          fix: 'Embedding service initialization',
          error: String(serviceError),
        });
      }
    }

    // ──────────────────────────────────────────────────────────────
    // Gap 2: Documents without OCR results (non-pending)
    // ──────────────────────────────────────────────────────────────
    const docsWithoutOCR = conn
      .prepare(
        `SELECT d.id FROM documents d
       LEFT JOIN ocr_results o ON o.document_id = d.id
       WHERE o.id IS NULL AND d.status NOT IN ('pending', 'processing')`
      )
      .all() as Array<{ id: string }>;

    gaps.documents_without_ocr = {
      count: docsWithoutOCR.length,
      sample_ids: docsWithoutOCR.slice(0, SAMPLE_LIMIT).map((r) => r.id),
      fixable: false,
      fix_tool: 'ocr_retry_failed',
      fix_hint:
        'Use ocr_process_pending to process pending docs, or ocr_retry_failed for failed ones',
    };

    // ──────────────────────────────────────────────────────────────
    // Gap 3: Images without VLM descriptions
    // ──────────────────────────────────────────────────────────────
    const imagesWithoutVLM = conn
      .prepare(
        `SELECT id FROM images
       WHERE vlm_status IN ('pending', 'failed') OR vlm_status IS NULL`
      )
      .all() as Array<{ id: string }>;

    gaps.images_without_vlm = {
      count: imagesWithoutVLM.length,
      sample_ids: imagesWithoutVLM.slice(0, SAMPLE_LIMIT).map((r) => r.id),
      fixable: false,
      fix_tool: 'ocr_vlm_process',
      fix_hint: null,
    };

    // ──────────────────────────────────────────────────────────────
    // Gap 4: Embeddings without vectors in vec_embeddings
    // ──────────────────────────────────────────────────────────────
    const embeddingsWithoutVectors = conn
      .prepare(
        `SELECT e.id FROM embeddings e
       LEFT JOIN vec_embeddings v ON v.embedding_id = e.id
       WHERE v.embedding_id IS NULL`
      )
      .all() as Array<{ id: string }>;

    gaps.embeddings_without_vectors = {
      count: embeddingsWithoutVectors.length,
      sample_ids: embeddingsWithoutVectors.slice(0, SAMPLE_LIMIT).map((r) => r.id),
      fixable: false,
      fix_tool: 'ocr_embedding_rebuild',
      fix_hint: 'Use include_vlm=true for VLM embeddings',
    };

    // ──────────────────────────────────────────────────────────────
    // Gap 5: Orphaned provenance records
    // Provenance records not referenced by any entity's provenance_id
    // ──────────────────────────────────────────────────────────────
    const orphanedProvenance = conn
      .prepare(
        `SELECT p.id FROM provenance p
       WHERE p.type = 'DOCUMENT' AND p.id NOT IN (SELECT provenance_id FROM documents WHERE provenance_id IS NOT NULL)
       UNION ALL
       SELECT p.id FROM provenance p
       WHERE p.type = 'OCR_RESULT' AND p.id NOT IN (SELECT provenance_id FROM ocr_results WHERE provenance_id IS NOT NULL)
       UNION ALL
       SELECT p.id FROM provenance p
       WHERE p.type = 'CHUNK' AND p.id NOT IN (SELECT provenance_id FROM chunks WHERE provenance_id IS NOT NULL)
       UNION ALL
       SELECT p.id FROM provenance p
       WHERE p.type = 'EMBEDDING' AND p.id NOT IN (SELECT provenance_id FROM embeddings WHERE provenance_id IS NOT NULL)
       UNION ALL
       SELECT p.id FROM provenance p
       WHERE p.type = 'IMAGE' AND p.id NOT IN (SELECT provenance_id FROM images WHERE provenance_id IS NOT NULL)
       LIMIT 100`
      )
      .all() as Array<{ id: string }>;

    gaps.orphaned_provenance = {
      count: orphanedProvenance.length,
      sample_ids: orphanedProvenance.slice(0, SAMPLE_LIMIT).map((r) => r.id),
      fixable: true,
      fix_tool: 'ocr_health_check',
      fix_hint: 'Set fix=true to delete orphaned provenance records that reference non-existent entities',
    };

    // Fix: Delete orphaned provenance records
    if (input.fix && orphanedProvenance.length > 0) {
      try {
        const orphanIds = orphanedProvenance.map((r) => r.id);

        // Clear self-references (parent_id/source_id) pointing to orphaned records
        // so deletion doesn't violate provenance self-referential FKs
        for (const orphanId of orphanIds) {
          conn.prepare('UPDATE provenance SET parent_id = NULL WHERE parent_id = ?').run(orphanId);
          conn.prepare('UPDATE provenance SET source_id = NULL WHERE source_id = ?').run(orphanId);
        }

        // Delete orphaned provenance records
        let deletedCount = 0;
        for (const orphanId of orphanIds) {
          const result = conn.prepare('DELETE FROM provenance WHERE id = ?').run(orphanId);
          deletedCount += result.changes;
        }

        fixes.push(`Deleted ${deletedCount} orphaned provenance records`);
      } catch (provCleanupError) {
        const errMsg = provCleanupError instanceof Error ? provCleanupError.message : String(provCleanupError);
        console.error(`[HealthCheck] Orphaned provenance cleanup failed: ${errMsg}`);
        fixFailures.push({
          fix: 'Orphaned provenance cleanup',
          error: errMsg,
        });
      }
    }

    // ──────────────────────────────────────────────────────────────
    // Gap 6: Pending documents that cannot process (missing API key)
    // ──────────────────────────────────────────────────────────────
    const pendingDocs = conn
      .prepare(`SELECT id FROM documents WHERE status = 'pending'`)
      .all() as Array<{ id: string }>;

    const pendingBlocked = !process.env.DATALAB_API_KEY && pendingDocs.length > 0;

    gaps.pending_documents_blocked = {
      count: pendingBlocked ? pendingDocs.length : 0,
      sample_ids: pendingBlocked ? pendingDocs.slice(0, SAMPLE_LIMIT).map((r) => r.id) : [],
      fixable: false,
      fix_tool: null,
      fix_hint: pendingBlocked
        ? 'Set DATALAB_API_KEY environment variable. In Docker, add -e DATALAB_API_KEY to docker run args.'
        : null,
    };

    // ──────────────────────────────────────────────────────────────
    // Summary statistics
    // ──────────────────────────────────────────────────────────────
    const totalDocuments = (
      conn.prepare('SELECT COUNT(*) as count FROM documents').get() as { count: number }
    ).count;
    const totalChunks = (
      conn.prepare('SELECT COUNT(*) as count FROM chunks').get() as { count: number }
    ).count;
    const totalEmbeddings = (
      conn.prepare('SELECT COUNT(*) as count FROM embeddings').get() as { count: number }
    ).count;
    const totalImages = (
      conn.prepare('SELECT COUNT(*) as count FROM images').get() as { count: number }
    ).count;

    // M-16: If ALL attempted fixes failed, throw an error
    const fixesAttempted = fixes.length + fixFailures.length;
    if (input.fix && fixesAttempted > 0 && fixes.length === 0 && fixFailures.length > 0) {
      const failureDetails = fixFailures.map(f => `  ${f.fix}: ${f.error}`).join('\n');
      throw new Error(`All ${fixFailures.length} fix attempt(s) failed:\n${failureDetails}`);
    }

    const totalGaps = Object.values(gaps).reduce((sum, g) => sum + g.count, 0);
    const healthy = totalGaps === 0 && envWarnings.length === 0;

    // Build dynamic next_steps based on gaps found
    const nextSteps: Array<{ tool: string; description: string }> = [];
    if (gaps.chunks_without_embeddings?.count > 0 || gaps.documents_without_ocr?.count > 0) {
      nextSteps.push({
        tool: 'ocr_process_pending',
        description: 'Process pending documents through the OCR pipeline',
      });
    }
    if (gaps.documents_without_ocr?.count > 0) {
      nextSteps.push({ tool: 'ocr_retry_failed', description: 'Retry failed documents' });
    }
    if (gaps.images_without_vlm?.count > 0) {
      nextSteps.push({
        tool: 'ocr_vlm_process',
        description: 'Generate VLM descriptions for images without them',
      });
    }
    if (envWarnings.length > 0) {
      nextSteps.push({
        tool: 'ocr_guide',
        description: 'View setup instructions for configuring API keys',
      });
    }
    if (nextSteps.length === 0 && healthy) {
      nextSteps.push({ tool: 'ocr_search', description: 'Search across all documents' });
    }

    return formatResponse(
      successResult({
        healthy,
        environment_status: environment,
        env_warnings: envWarnings.length > 0 ? envWarnings : undefined,
        total_gaps: totalGaps,
        gaps,
        fixes_applied: fixes.length > 0 ? fixes : undefined,
        fix_failures: fixFailures.length > 0 ? fixFailures : undefined,
        fixes_succeeded: fixes.length,
        fixes_failed: fixFailures.length,
        summary: {
          total_documents: totalDocuments,
          total_chunks: totalChunks,
          total_embeddings: totalEmbeddings,
          total_images: totalImages,
        },
        next_steps: nextSteps,
      })
    );
  } catch (error) {
    return handleError(error);
  }
}

// ═══════════════════════════════════════════════════════════════════════════════
// TOOL DEFINITIONS EXPORT
// ═══════════════════════════════════════════════════════════════════════════════

/**
 * Health check tools collection for MCP server registration
 */
export const healthTools: Record<string, ToolDefinition> = {
  ocr_health_check: {
    description:
      '[ESSENTIAL] Diagnose data integrity issues: missing embeddings, orphaned provenance, VLM gaps. Set fix=true to auto-repair.',
    inputSchema: HealthCheckInput.shape,
    handler: handleHealthCheck,
  },
};
